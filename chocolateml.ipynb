{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Read the JSON file\n",
    "with open('hist_eval.json', 'r') as file:\n",
    "    labels_data = json.load(file)\n",
    "\n",
    "# Extract image names and critical scores\n",
    "# image_names = list(labels_data.keys())\n",
    "image_names_from_json = list(labels_data.keys())\n",
    "image_names_with_raw_suffix = [\"./critical_hist_chunk_test/_corrected_cells/\"+ name[:-4] + '_raw.jpg' for name in image_names_from_json]\n",
    "\n",
    "critical_scores = [labels_data[image]['citicality_score'] for image in image_names_from_json]\n",
    "\n",
    "#critical score and image names loaded from hist_eval.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image_path):\n",
    "    # Load image as grayscale\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # blurred_image = cv2.GaussianBlur(image, (9, 9), 2) \n",
    "\n",
    "    #morphologyical filter applied\n",
    "    kernel = np.ones((7, 7), np.uint8)\n",
    "    morph_image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    return morph_image\n",
    "\n",
    "# Preprocess all images and store them in a list\n",
    "preprocessed_images = [preprocess_image(image_path) for image_path in image_names_with_raw_suffix]\n",
    "\n",
    "# Set the maximum width for plots\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 6)\n",
    "\n",
    "# Create subplots for original images\n",
    "fig, axs = plt.subplots(1, 5)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(10,15):\n",
    "    image_path = image_names_with_raw_suffix[i]\n",
    "    image = cv2.imread(image_path)\n",
    "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    axs[i-10].imshow(image)\n",
    "    axs[i-10].set_title('{}'.format(image_names_from_json[i][:27]))  # Display first 20 characters of the name\n",
    "    axs[i-10].axis('off')\n",
    "\n",
    "# Save the figure with maximum width\n",
    "plt.savefig('original_images.png', bbox_inches='tight')\n",
    "\n",
    "# Create subplots for preprocessed images\n",
    "fig, axs = plt.subplots(1, 5)\n",
    "fig.tight_layout(pad=3.0)\n",
    "\n",
    "for i in range(10,15):\n",
    "    image_path = image_names_with_raw_suffix[i]\n",
    "\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # Apply Sobel edge detection\n",
    "    axs[i-10].imshow(preprocessed_images[i], cmap='gray')\n",
    "    axs[i-10].set_title('{}'.format(image_names_from_json[i][:27]))  # Display first 20 characters of the name\n",
    "    axs[i-10].axis('off')\n",
    "    print(image_names_from_json[i][:27],critical_scores[i])\n",
    "# Save the figure with maximum width\n",
    "plt.savefig('preprocessed_images.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#5 of the original and corresponding preprocessed images displayed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define a transform to resize the images to the desired dimensions\n",
    "def resize_image(image, target_size):\n",
    "    resized_image = cv2.resize(image, target_size)\n",
    "    return resized_image\n",
    "\n",
    "# Define a simple CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = nn.Linear(32 * 26 * 6, 128)  # Adjusted input size after resizing\n",
    "        self.fc2 = nn.Linear(128, 1)  # Output layer for regression\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x = self.pool(torch.relu(self.conv1(x)))\n",
    "        # print(x.shape)\n",
    "        x = self.pool(torch.relu(self.conv2(x)))\n",
    "        # print(x.shape)\n",
    "        x = x.view(-1, 32 * 26 * 6)  # Adjusted input size after resizing\n",
    "        # print(x.shape)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # print(x.shape)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, images, labels):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Resize all images to a consistent size\n",
    "target_size = (25, 105)  \n",
    "resized_images = [resize_image(image, target_size) for image in preprocessed_images]\n",
    "\n",
    "# Convert resized images and labels to PyTorch tensors\n",
    "images_tensor = torch.tensor(resized_images, dtype=torch.float32).unsqueeze(1).to(device) \n",
    "labels_tensor = torch.tensor(critical_scores, dtype=torch.float32).unsqueeze(1).to(device)\n",
    "\n",
    "# print(images_tensor)\n",
    "# Split dataset into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(images_tensor, labels_tensor, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create PyTorch DataLoader for training and validation sets\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataset = CustomDataset(X_val, y_val)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = CNN().to(device)\n",
    "criterion = nn.SmoothL1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 100  # Maximum number of epochs\n",
    "patience = 10      # Number of epochs to wait for improvement\n",
    "best_val_loss = float('inf')\n",
    "no_improvement = 0\n",
    "\n",
    "\n",
    "# Train the model\n",
    "# num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # print(images.shape)\n",
    "        outputs = model(images)\n",
    "        # print(outputs.shape)\n",
    "        # labels = labels.view(-1, 1)\n",
    "        # print(\"lable\",labels.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            outputs = model(images)\n",
    "            val_loss += criterion(outputs, labels).item() * images.size(0)\n",
    "    epoch_val_loss = val_loss / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss}, Validation Loss: {epoch_val_loss}\")\n",
    "\n",
    "    # Check for improvement in validation loss\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        no_improvement = 0\n",
    "        # Save the model\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        no_improvement += 1\n",
    "        if no_improvement >= patience:\n",
    "            print(f\"No improvement in validation loss for {patience} epochs. Stopping training.\")\n",
    "            break\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'cnn_model.pth')\n",
    "\n",
    "#Training done using the cnn model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_scores = []\n",
    "original_scores = []\n",
    "\n",
    "# Switch model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Iterate over validation dataset\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        # Convert predictions and labels to numpy arrays\n",
    "        predicted_scores.extend(outputs.cpu().detach().numpy().flatten())\n",
    "        original_scores.extend(labels.cpu().detach().numpy().flatten())\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "predicted_scores = np.array(predicted_scores)\n",
    "\n",
    "# Clip the scores to have a minimum value of 20\n",
    "predicted_scores = np.maximum(predicted_scores, 20)\n",
    "\n",
    "# Round the scores to whole numbers\n",
    "predicted_scores = np.round(predicted_scores)\n",
    "\n",
    "# original_scores = np.array(original_scores)\n",
    "\n",
    "# compare predicted_scores and original_scores using scatter plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(original_scores, predicted_scores, color='green', alpha=0.5)\n",
    "plt.plot([min(original_scores), max(original_scores)], [min(original_scores), max(original_scores)], color='grey', linestyle='--')\n",
    "plt.title('Comparison of Predicted and Original Critical Scores')\n",
    "plt.xlabel('Original Critical Scores')\n",
    "plt.ylabel('Predicted Critical Scores')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# compare]ison predicted_scores and original_scores displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to preprocess images in the folder\n",
    "def preprocess_images_in_folder(folder_path):\n",
    "    preprocessed_images = []\n",
    "    image_names = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            preprocessed_image = preprocess_image(image_path)\n",
    "            preprocessed_images.append(resize_image(preprocessed_image, target_size))\n",
    "            image_names.append(filename)\n",
    "    return preprocessed_images, image_names\n",
    "\n",
    "folder_a_path = './critical_hist_chunk_test/_corrected_cells/'\n",
    "preprocessed_images_folder_a, image_names_folder_a = preprocess_images_in_folder(folder_a_path)\n",
    "\n",
    "# Load the trained model\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Make predictions\n",
    "predicted_critical_scores = {}\n",
    "for i in range(len(preprocessed_images_folder_a)):\n",
    "    image = preprocessed_images_folder_a[i]\n",
    "    image_name = image_names_folder_a[i]\n",
    "    image_tensor = torch.tensor(image, dtype=torch.float32).unsqueeze(0).unsqueeze(1).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "    predicted_critical_scores[image_name] = output.item()\n",
    "\n",
    "# Iterate through the dictionary and modify the critical values to have a minimum value of 20 and to make values whole numbers\n",
    "for key, value in predicted_critical_scores.items():\n",
    "    # Check if the value is less than 20\n",
    "    if value < 20:\n",
    "        # Set the value to 20\n",
    "        predicted_critical_scores[key] = 20\n",
    "    else:\n",
    "        # Round the score to a whole number\n",
    "        predicted_critical_scores[key] = round(value)\n",
    "\n",
    "# Save predicted critical scores to a JSON file\n",
    "output_json_path = './predicted_critical_scores.json'\n",
    "with open(output_json_path, 'w') as f:\n",
    "    json.dump(predicted_critical_scores, f)\n",
    "\n",
    "print(\"Predictions saved to:\", output_json_path)\n",
    "\n",
    "#predictions made for the whole dataset and saved to the json file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('mlvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fd81594f5f18064157b34cf7a83af75feeaefe5ec4d82b79aefad83216de6fab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
